{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选取数据集Trending YouTube Video Statistics中的 youtube_USvideos使用Apriori算法进行关联规则挖掘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据处理：对数据集进行处理，转换成适合关联规则挖掘的形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "color=sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm,skew\n",
    "pd.set_option('display.float_format',lambda x:'{:.3f}'.format(x))\n",
    "\n",
    "df1=pd.read_csv('./youtube-new/USvideos.csv')\n",
    " \n",
    "def loadDataSet():\n",
    "    clean_data = pd.DataFrame(pd.read_csv(\"./youtube-new/USvideos.csv\"))\n",
    "    new_data = []\n",
    "    # 关联规则挖掘数据处理\n",
    "    for v in range(1, len(clean_data)):\n",
    "        item = []\n",
    "        item.append(\"category_id\" + '='+ str(clean_data.loc[v,'category_id']))\n",
    "        item.append(\"comments_disabled\" + '='+ str(clean_data.loc[v,'comments_disabled']))\n",
    "        item.append(\"ratings_disabled\" + '='+ str(clean_data.loc[v,'ratings_disabled']))\n",
    "        item.append(\"video_error_or_removed\" + '='+ str(clean_data.loc[v,'video_error_or_removed']))\n",
    "        #print(item)\n",
    "        new_data.append(item)\n",
    "    print(len(new_data))\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "找出频繁项集，满足最小支持度阈值的所有项集，最小支持度设置为0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取候选1项集，dataSet为事务集。返回一个list，每个元素都是set集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createC1(dataSet):\n",
    "    C1 = []  \n",
    "    for transaction in dataSet:\n",
    "        for item in transaction:\n",
    "            if not [item] in C1:\n",
    "                C1.append([item])\n",
    "    C1.sort() \n",
    "    return list(map(frozenset, C1))  \n",
    "\n",
    "\n",
    "def scanD(dataSet, Ck, minSupport):\n",
    "    ssCnt = {}   \n",
    "    for tid in dataSet:\n",
    "        for can in Ck:\n",
    "            if can.issubset(tid):\n",
    "                ssCnt[can] = ssCnt.get(can, 0) + 1   \n",
    "    numItems = float(len(dataSet))\n",
    "    retList = []\n",
    "    supportData = {}\n",
    "    for key in ssCnt:\n",
    "        support = ssCnt[key] / numItems\n",
    "        if support >= minSupport:\n",
    "            retList.insert(0, key)  \n",
    "        supportData[key] = support\n",
    "    return retList, supportData "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成候选项集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aprioriGen(Lk, k):\n",
    "    retList = []\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i + 1, lenLk):\n",
    "            L1 = list(Lk[i])[:k-2]; L2 = list(Lk[j])[:k-2]   \n",
    "            L1.sort(); L2.sort()\n",
    "            if L1 == L2:\n",
    "                retList.append(Lk[i] | Lk[j])\n",
    "    return retList\n",
    "\n",
    "# 获取事务集中的所有的频繁项集\n",
    "\n",
    "def apriori(dataSet, minSupport=0.5):\n",
    "    C1 = createC1(dataSet)  \n",
    "    D = list(map(set, dataSet))  \n",
    "    L1, supportData = scanD(D, C1, minSupport)  \n",
    "    L = [L1]  \n",
    "    k = 2\n",
    "    while (len(L[k-2]) > 0):\n",
    "        Ck = aprioriGen(L[k-2], k)  \n",
    "        Lk, supK = scanD(D, Ck, minSupport)  \n",
    "        L.append(Lk);supportData.update(supK)  \n",
    "        k += 1\n",
    "    return L, supportData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成关联规则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40948\n",
      "[[frozenset({'video_error_or_removed=False'}), frozenset({'ratings_disabled=False'}), frozenset({'comments_disabled=False'})], [frozenset({'ratings_disabled=False', 'comments_disabled=False'}), frozenset({'video_error_or_removed=False', 'comments_disabled=False'}), frozenset({'video_error_or_removed=False', 'ratings_disabled=False'})], [frozenset({'video_error_or_removed=False', 'comments_disabled=False', 'ratings_disabled=False'})], []] {frozenset({'category_id=24'}): 0.24333300771710462, frozenset({'comments_disabled=False'}): 0.984541369541858, frozenset({'ratings_disabled=False'}): 0.9958728143010648, frozenset({'video_error_or_removed=False'}): 0.9994383120054704, frozenset({'category_id=23'}): 0.08442414769952135, frozenset({'category_id=28'}): 0.058635342385464494, frozenset({'category_id=1'}): 0.05726775422487057, frozenset({'category_id=25'}): 0.060735567060662306, frozenset({'category_id=17'}): 0.053091726091628405, frozenset({'category_id=10'}): 0.15805411741721206, frozenset({'category_id=15'}): 0.022467519781185896, frozenset({'category_id=27'}): 0.04044153560613461, frozenset({'category_id=26'}): 0.1012503663182573, frozenset({'category_id=2'}): 0.009377747386929765, frozenset({'comments_disabled=True'}): 0.015458630458142034, frozenset({'category_id=19'}): 0.009817329295692097, frozenset({'category_id=22'}): 0.07836768584546254, frozenset({'category_id=20'}): 0.01995213441437921, frozenset({'ratings_disabled=True'}): 0.004127185698935235, frozenset({'video_error_or_removed=True'}): 0.0005616879945296474, frozenset({'category_id=29'}): 0.001392009377747387, frozenset({'category_id=43'}): 0.001392009377747387, frozenset({'video_error_or_removed=False', 'ratings_disabled=False'}): 0.9953111263065351, frozenset({'video_error_or_removed=False', 'comments_disabled=False'}): 0.9839796815473283, frozenset({'ratings_disabled=False', 'comments_disabled=False'}): 0.9830028328611898, frozenset({'video_error_or_removed=False', 'comments_disabled=False', 'ratings_disabled=False'}): 0.9824411448666601}\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    dataSet = loadDataSet()  \n",
    "    L, suppData = apriori(dataSet,minSupport=0.7)\n",
    "    print(L,suppData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关联规则，其支持度和置信度结果如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40948\n",
      "[[frozenset({'video_error_or_removed=False'}), frozenset({'ratings_disabled=False'}), frozenset({'comments_disabled=False'})], [frozenset({'ratings_disabled=False', 'comments_disabled=False'}), frozenset({'video_error_or_removed=False', 'comments_disabled=False'}), frozenset({'video_error_or_removed=False', 'ratings_disabled=False'})], [frozenset({'video_error_or_removed=False', 'comments_disabled=False', 'ratings_disabled=False'})], []] {frozenset({'category_id=24'}): 0.24333300771710462, frozenset({'comments_disabled=False'}): 0.984541369541858, frozenset({'ratings_disabled=False'}): 0.9958728143010648, frozenset({'video_error_or_removed=False'}): 0.9994383120054704, frozenset({'category_id=23'}): 0.08442414769952135, frozenset({'category_id=28'}): 0.058635342385464494, frozenset({'category_id=1'}): 0.05726775422487057, frozenset({'category_id=25'}): 0.060735567060662306, frozenset({'category_id=17'}): 0.053091726091628405, frozenset({'category_id=10'}): 0.15805411741721206, frozenset({'category_id=15'}): 0.022467519781185896, frozenset({'category_id=27'}): 0.04044153560613461, frozenset({'category_id=26'}): 0.1012503663182573, frozenset({'category_id=2'}): 0.009377747386929765, frozenset({'comments_disabled=True'}): 0.015458630458142034, frozenset({'category_id=19'}): 0.009817329295692097, frozenset({'category_id=22'}): 0.07836768584546254, frozenset({'category_id=20'}): 0.01995213441437921, frozenset({'ratings_disabled=True'}): 0.004127185698935235, frozenset({'video_error_or_removed=True'}): 0.0005616879945296474, frozenset({'category_id=29'}): 0.001392009377747387, frozenset({'category_id=43'}): 0.001392009377747387, frozenset({'video_error_or_removed=False', 'ratings_disabled=False'}): 0.9953111263065351, frozenset({'video_error_or_removed=False', 'comments_disabled=False'}): 0.9839796815473283, frozenset({'ratings_disabled=False', 'comments_disabled=False'}): 0.9830028328611898, frozenset({'video_error_or_removed=False', 'comments_disabled=False', 'ratings_disabled=False'}): 0.9824411448666601}\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Apr 26 16:31:10 2019\n",
    "\n",
    "@author: admin\n",
    "\"\"\"\n",
    "\n",
    "from numpy import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "color=sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm,skew\n",
    "pd.set_option('display.float_format',lambda x:'{:.3f}'.format(x))\n",
    "\n",
    "df1=pd.read_csv('./youtube-new/USvideos.csv')\n",
    " \n",
    "def loadDataSet():\n",
    "    clean_data = pd.DataFrame(pd.read_csv(\"./youtube-new/USvideos.csv\"))\n",
    "    new_data = []\n",
    "    # 关联规则挖掘数据处理\n",
    "    for v in range(1, len(clean_data)):\n",
    "        item = []\n",
    "        item.append(\"category_id\" + '='+ str(clean_data.loc[v,'category_id']))\n",
    "        item.append(\"comments_disabled\" + '='+ str(clean_data.loc[v,'comments_disabled']))\n",
    "        item.append(\"ratings_disabled\" + '='+ str(clean_data.loc[v,'ratings_disabled']))\n",
    "        item.append(\"video_error_or_removed\" + '='+ str(clean_data.loc[v,'video_error_or_removed']))\n",
    "        #print(item)\n",
    "        new_data.append(item)\n",
    "    print(len(new_data))\n",
    "    return new_data\n",
    "\n",
    " \n",
    "# 获取候选1项集，dataSet为事务集。返回一个list，每个元素都是set集合\n",
    "def createC1(dataSet):\n",
    "    C1 = []   # 元素个数为1的项集（非频繁项集，因为还没有同最小支持度比较）\n",
    "    for transaction in dataSet:\n",
    "        for item in transaction:\n",
    "            if not [item] in C1:\n",
    "                C1.append([item])\n",
    "    C1.sort()  # 这里排序是为了，生成新的候选集时可以直接认为两个n项候选集前面的部分相同\n",
    "    # 因为除了候选1项集外其他的候选n项集都是以二维列表的形式存在，所以要将候选1项集的每一个元素都转化为一个单独的集合。\n",
    "    return list(map(frozenset, C1))   #map(frozenset, C1)的语义是将C1由Python列表转换为不变集合（frozenset，Python中的数据结构）\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 找出候选集中的频繁项集\n",
    "# dataSet为全部数据集，Ck为大小为k（包含k个元素）的候选项集，minSupport为设定的最小支持度\n",
    "def scanD(dataSet, Ck, minSupport):\n",
    "    ssCnt = {}   # 记录每个候选项的个数\n",
    "    for tid in dataSet:\n",
    "        for can in Ck:\n",
    "            if can.issubset(tid):\n",
    "                ssCnt[can] = ssCnt.get(can, 0) + 1   # 计算每一个项集出现的频率\n",
    "    numItems = float(len(dataSet))\n",
    "    retList = []\n",
    "    supportData = {}\n",
    "    for key in ssCnt:\n",
    "        support = ssCnt[key] / numItems\n",
    "        if support >= minSupport:\n",
    "            retList.insert(0, key)  #将频繁项集插入返回列表的首部\n",
    "        supportData[key] = support\n",
    "    return retList, supportData   #retList为在Ck中找出的频繁项集（支持度大于minSupport的），supportData记录各频繁项集的支持度\n",
    "\n",
    "\n",
    "# 通过频繁项集列表Lk和项集个数k生成候选项集C(k+1)。\n",
    "def aprioriGen(Lk, k):\n",
    "    retList = []\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i + 1, lenLk):\n",
    "            # 前k-1项相同时，才将两个集合合并，合并后才能生成k+1项\n",
    "            L1 = list(Lk[i])[:k-2]; L2 = list(Lk[j])[:k-2]   # 取出两个集合的前k-1个元素\n",
    "            L1.sort(); L2.sort()\n",
    "            if L1 == L2:\n",
    "                retList.append(Lk[i] | Lk[j])\n",
    "    return retList\n",
    "\n",
    "# 获取事务集中的所有的频繁项集\n",
    "# Ck表示项数为k的候选项集，最初的C1通过createC1()函数生成。Lk表示项数为k的频繁项集，supK为其支持度，Lk和supK由scanD()函数通过Ck计算而来。\n",
    "def apriori(dataSet, minSupport=0.5):\n",
    "    C1 = createC1(dataSet)  # 从事务集中获取候选1项集\n",
    "    D = list(map(set, dataSet))  # 将事务集的每个元素转化为集合\n",
    "    L1, supportData = scanD(D, C1, minSupport)  # 获取频繁1项集和对应的支持度\n",
    "    L = [L1]  # L用来存储所有的频繁项集\n",
    "    k = 2\n",
    "    while (len(L[k-2]) > 0): # 一直迭代到项集数目过大而在事务集中不存在这种n项集\n",
    "        Ck = aprioriGen(L[k-2], k)   # 根据频繁项集生成新的候选项集。Ck表示项数为k的候选项集\n",
    "        Lk, supK = scanD(D, Ck, minSupport)  # Lk表示项数为k的频繁项集，supK为其支持度\n",
    "        L.append(Lk);supportData.update(supK)  # 添加新频繁项集和他们的支持度\n",
    "        k += 1\n",
    "    return L, supportData\n",
    "\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    dataSet = loadDataSet()  # 获取事务集。每个元素都是列表\n",
    "    # C1 = createC1(dataSet)  # 获取候选1项集。每个元素都是集合\n",
    "    # D = list(map(set, dataSet))  # 转化事务集的形式，每个元素都转化为集合。\n",
    "    # L1, suppDat = scanD(D, C1, 0.5)\n",
    "    # print(L1,suppDat)\n",
    "\n",
    "\n",
    "    L, suppData = apriori(dataSet,minSupport=0.7)\n",
    "    print(L,suppData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40948\n",
      "[[frozenset({'video_error_or_removed=False'}), frozenset({'ratings_disabled=False'}), frozenset({'comments_disabled=False'})], [frozenset({'ratings_disabled=False', 'comments_disabled=False'}), frozenset({'video_error_or_removed=False', 'comments_disabled=False'}), frozenset({'video_error_or_removed=False', 'ratings_disabled=False'})], [frozenset({'video_error_or_removed=False', 'comments_disabled=False', 'ratings_disabled=False'})], []] {frozenset({'category_id=24'}): 0.24333300771710462, frozenset({'comments_disabled=False'}): 0.984541369541858, frozenset({'ratings_disabled=False'}): 0.9958728143010648, frozenset({'video_error_or_removed=False'}): 0.9994383120054704, frozenset({'category_id=23'}): 0.08442414769952135, frozenset({'category_id=28'}): 0.058635342385464494, frozenset({'category_id=1'}): 0.05726775422487057, frozenset({'category_id=25'}): 0.060735567060662306, frozenset({'category_id=17'}): 0.053091726091628405, frozenset({'category_id=10'}): 0.15805411741721206, frozenset({'category_id=15'}): 0.022467519781185896, frozenset({'category_id=27'}): 0.04044153560613461, frozenset({'category_id=26'}): 0.1012503663182573, frozenset({'category_id=2'}): 0.009377747386929765, frozenset({'comments_disabled=True'}): 0.015458630458142034, frozenset({'category_id=19'}): 0.009817329295692097, frozenset({'category_id=22'}): 0.07836768584546254, frozenset({'category_id=20'}): 0.01995213441437921, frozenset({'ratings_disabled=True'}): 0.004127185698935235, frozenset({'video_error_or_removed=True'}): 0.0005616879945296474, frozenset({'category_id=29'}): 0.001392009377747387, frozenset({'category_id=43'}): 0.001392009377747387, frozenset({'video_error_or_removed=False', 'ratings_disabled=False'}): 0.9953111263065351, frozenset({'video_error_or_removed=False', 'comments_disabled=False'}): 0.9839796815473283, frozenset({'ratings_disabled=False', 'comments_disabled=False'}): 0.9830028328611898, frozenset({'video_error_or_removed=False', 'comments_disabled=False', 'ratings_disabled=False'}): 0.9824411448666601}\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Apr 26 16:31:10 2019\n",
    "\n",
    "@author: admin\n",
    "\"\"\"\n",
    "\n",
    "from numpy import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "color=sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm,skew\n",
    "pd.set_option('display.float_format',lambda x:'{:.3f}'.format(x))\n",
    "\n",
    "df1=pd.read_csv('./youtube-new/USvideos.csv')\n",
    " \n",
    "def loadDataSet():\n",
    "    clean_data = pd.DataFrame(pd.read_csv(\"./youtube-new/USvideos.csv\"))\n",
    "    new_data = []\n",
    "    # 关联规则挖掘数据处理\n",
    "    for v in range(1, len(clean_data)):\n",
    "        item = []\n",
    "        item.append(\"category_id\" + '='+ str(clean_data.loc[v,'category_id']))\n",
    "        item.append(\"comments_disabled\" + '='+ str(clean_data.loc[v,'comments_disabled']))\n",
    "        item.append(\"ratings_disabled\" + '='+ str(clean_data.loc[v,'ratings_disabled']))\n",
    "        item.append(\"video_error_or_removed\" + '='+ str(clean_data.loc[v,'video_error_or_removed']))\n",
    "        #print(item)\n",
    "        new_data.append(item)\n",
    "    print(len(new_data))\n",
    "    return new_data\n",
    "\n",
    " \n",
    "# 获取候选1项集，dataSet为事务集。返回一个list，每个元素都是set集合\n",
    "def createC1(dataSet):\n",
    "    C1 = []   # 元素个数为1的项集（非频繁项集，因为还没有同最小支持度比较）\n",
    "    for transaction in dataSet:\n",
    "        for item in transaction:\n",
    "            if not [item] in C1:\n",
    "                C1.append([item])\n",
    "    C1.sort()  # 这里排序是为了，生成新的候选集时可以直接认为两个n项候选集前面的部分相同\n",
    "    # 因为除了候选1项集外其他的候选n项集都是以二维列表的形式存在，所以要将候选1项集的每一个元素都转化为一个单独的集合。\n",
    "    return list(map(frozenset, C1))   #map(frozenset, C1)的语义是将C1由Python列表转换为不变集合（frozenset，Python中的数据结构）\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 找出候选集中的频繁项集\n",
    "# dataSet为全部数据集，Ck为大小为k（包含k个元素）的候选项集，minSupport为设定的最小支持度\n",
    "def scanD(dataSet, Ck, minSupport):\n",
    "    ssCnt = {}   # 记录每个候选项的个数\n",
    "    for tid in dataSet:\n",
    "        for can in Ck:\n",
    "            if can.issubset(tid):\n",
    "                ssCnt[can] = ssCnt.get(can, 0) + 1   # 计算每一个项集出现的频率\n",
    "    numItems = float(len(dataSet))\n",
    "    retList = []\n",
    "    supportData = {}\n",
    "    for key in ssCnt:\n",
    "        support = ssCnt[key] / numItems\n",
    "        if support >= minSupport:\n",
    "            retList.insert(0, key)  #将频繁项集插入返回列表的首部\n",
    "        supportData[key] = support\n",
    "    return retList, supportData   #retList为在Ck中找出的频繁项集（支持度大于minSupport的），supportData记录各频繁项集的支持度\n",
    "\n",
    "\n",
    "# 通过频繁项集列表Lk和项集个数k生成候选项集C(k+1)。\n",
    "def aprioriGen(Lk, k):\n",
    "    retList = []\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i + 1, lenLk):\n",
    "            # 前k-1项相同时，才将两个集合合并，合并后才能生成k+1项\n",
    "            L1 = list(Lk[i])[:k-2]; L2 = list(Lk[j])[:k-2]   # 取出两个集合的前k-1个元素\n",
    "            L1.sort(); L2.sort()\n",
    "            if L1 == L2:\n",
    "                retList.append(Lk[i] | Lk[j])\n",
    "    return retList\n",
    "\n",
    "# 获取事务集中的所有的频繁项集\n",
    "# Ck表示项数为k的候选项集，最初的C1通过createC1()函数生成。Lk表示项数为k的频繁项集，supK为其支持度，Lk和supK由scanD()函数通过Ck计算而来。\n",
    "def apriori(dataSet, minSupport=0.5):\n",
    "    C1 = createC1(dataSet)  # 从事务集中获取候选1项集\n",
    "    D = list(map(set, dataSet))  # 将事务集的每个元素转化为集合\n",
    "    L1, supportData = scanD(D, C1, minSupport)  # 获取频繁1项集和对应的支持度\n",
    "    L = [L1]  # L用来存储所有的频繁项集\n",
    "    k = 2\n",
    "    while (len(L[k-2]) > 0): # 一直迭代到项集数目过大而在事务集中不存在这种n项集\n",
    "        Ck = aprioriGen(L[k-2], k)   # 根据频繁项集生成新的候选项集。Ck表示项数为k的候选项集\n",
    "        Lk, supK = scanD(D, Ck, minSupport)  # Lk表示项数为k的频繁项集，supK为其支持度\n",
    "        L.append(Lk);supportData.update(supK)  # 添加新频繁项集和他们的支持度\n",
    "        k += 1\n",
    "    return L, supportData\n",
    "\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    dataSet = loadDataSet()  # 获取事务集。每个元素都是列表\n",
    "    # C1 = createC1(dataSet)  # 获取候选1项集。每个元素都是集合\n",
    "    # D = list(map(set, dataSet))  # 转化事务集的形式，每个元素都转化为集合。\n",
    "    # L1, suppDat = scanD(D, C1, 0.5)\n",
    "    # print(L1,suppDat)\n",
    "\n",
    "\n",
    "    L, suppData = apriori(dataSet,minSupport=0.3)\n",
    "    print(L,suppData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，一旦降低可信度阈值，就可以获得更多的规则。\n",
    "修改过后只有支持度不小于 0.3 的项集被选中到 L 中作为频繁项集，根据不同的需求，我们可以设定最小支持度的值，从而得到我们想要的频繁项集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对规则进行提升度（lift）评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40948\n",
      "frozenset({'ratings_disabled=False'}) --> frozenset({'comments_disabled=False'}) 支持度为： 1.0 置信度为： 0.9870766816253465 lift值为： 1.0\n",
      "frozenset({'comments_disabled=False'}) --> frozenset({'ratings_disabled=False'}) 支持度为： 0.98 置信度为： 0.9984373062135682 lift值为： 1.0\n",
      "frozenset({'category_id=24'}) --> frozenset({'ratings_disabled=False'}) 支持度为： 0.24 置信度为： 0.9969891609795263 lift值为： 1.0\n",
      "frozenset({'comments_disabled=False', 'category_id=24'}) --> frozenset({'ratings_disabled=False'}) 支持度为： 0.24 置信度为： 0.9988738738738739 lift值为： 1.0\n",
      "frozenset({'category_id=24'}) --> frozenset({'ratings_disabled=False', 'video_error_or_removed=False'}) 支持度为： 0.24 置信度为： 0.9961862705740666 lift值为： 1.0\n",
      "frozenset({'video_error_or_removed=False', 'category_id=24'}) --> frozenset({'ratings_disabled=False'}) 支持度为： 0.24 置信度为： 0.9969867416633186 lift值为： 1.0\n",
      "frozenset({'comments_disabled=False'}) --> frozenset({'video_error_or_removed=False', 'ratings_disabled=False'}) 支持度为： 0.98 置信度为： 0.9978667989582041 lift值为： 1.0\n",
      "frozenset({'comments_disabled=False', 'video_error_or_removed=False'}) --> frozenset({'ratings_disabled=False'}) 支持度为： 0.98 置信度为： 0.9984364141765114 lift值为： 1.0\n",
      "frozenset({'video_error_or_removed=False', 'ratings_disabled=False'}) --> frozenset({'comments_disabled=False'}) 支持度为： 1.0 置信度为： 0.9870693885562862 lift值为： 1.0\n",
      "frozenset({'ratings_disabled=False'}) --> frozenset({'comments_disabled=False', 'video_error_or_removed=False'}) 支持度为： 1.0 置信度为： 0.9865126658329041 lift值为： 1.0\n",
      "frozenset({'comments_disabled=False', 'category_id=24'}) --> frozenset({'ratings_disabled=False', 'video_error_or_removed=False'}) 支持度为： 0.24 置信度为： 0.9980548730548731 lift值为： 1.0\n",
      "frozenset({'comments_disabled=False', 'category_id=24', 'video_error_or_removed=False'}) --> frozenset({'ratings_disabled=False'}) 支持度为： 0.24 置信度为： 0.9988729508196721 lift值为： 1.0\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "color=sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy import stats\n",
    "from scipy.stats import norm,skew\n",
    "pd.set_option('display.float_format',lambda x:'{:.3f}'.format(x))\n",
    "\n",
    " \n",
    "\n",
    "def loadDataSet():\n",
    "    clean_data = pd.DataFrame(pd.read_csv(\"./youtube-new/USvideos.csv\"))\n",
    "    new_data = []\n",
    "    # 关联规则挖掘数据处理\n",
    "    for v in range(1, len(clean_data)):\n",
    "        item = []\n",
    "        item.append(\"category_id\" + '='+ str(clean_data.loc[v,'category_id']))\n",
    "        item.append(\"comments_disabled\" + '='+ str(clean_data.loc[v,'comments_disabled']))\n",
    "        item.append(\"ratings_disabled\" + '='+ str(clean_data.loc[v,'ratings_disabled']))\n",
    "        item.append(\"video_error_or_removed\" + '='+ str(clean_data.loc[v,'video_error_or_removed']))\n",
    "        #print(item)\n",
    "        new_data.append(item)\n",
    "    print(len(new_data))\n",
    "    return new_data\n",
    "\n",
    " \n",
    " \n",
    "def createC1(dataSet):\n",
    "    C1 = []\n",
    "    for transaction in dataSet:\n",
    "        for item in transaction:\n",
    "            if not [item] in C1:\n",
    "                C1.append([item])\n",
    "    C1.sort()\n",
    "    # 映射为frozenset唯一性的，可使用其构造字典\n",
    "    return list(map(frozenset, C1))      \n",
    " \n",
    " \n",
    "# 从候选K项集到频繁K项集（支持度计算）\n",
    "def scanD(D, Ck, minSupport):\n",
    "    ssCnt = {}\n",
    "    for tid in D:\n",
    "        for can in Ck:\n",
    "            if can.issubset(tid):\n",
    "                if not can in ssCnt:\n",
    "                    ssCnt[can] = 1\n",
    "                else:\n",
    "                    ssCnt[can] += 1\n",
    "    numItems = float(len(D))\n",
    "    retList = []\n",
    "    supportData = {}\n",
    "    for key in ssCnt:\n",
    "        support = ssCnt[key] / numItems\n",
    "        if support >= minSupport:\n",
    "            retList.insert(0, key)\n",
    "            supportData[key] = support  \n",
    "    return retList, supportData\n",
    " \n",
    " \n",
    "def calSupport(D, Ck, min_support):\n",
    "    dict_sup = {}\n",
    "    for i in D:\n",
    "        for j in Ck:\n",
    "            if j.issubset(i):\n",
    "                if not j in dict_sup:\n",
    "                    dict_sup[j] = 1\n",
    "                else:\n",
    "                    dict_sup[j] += 1\n",
    "    sumCount = float(len(D))\n",
    "    supportData = {}\n",
    "    relist = []\n",
    "    for i in dict_sup:\n",
    "        temp_sup = dict_sup[i] / sumCount\n",
    "        if temp_sup >= min_support:\n",
    "            relist.append(i)\n",
    "            supportData[i] = temp_sup  # 此处可设置返回全部的支持度数据（或者频繁项集的支持度数据）\n",
    "    return relist, supportData\n",
    " \n",
    " \n",
    "# 改进剪枝算法\n",
    "def aprioriGen(Lk, k):  # 创建候选K项集 ##LK为频繁K项集\n",
    "    retList = []\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i + 1, lenLk):\n",
    "            L1 = list(Lk[i])[:k - 2]\n",
    "            L2 = list(Lk[j])[:k - 2]\n",
    "            L1.sort()\n",
    "            L2.sort()\n",
    "            if L1 == L2:  # 前k-1项相等，则可相乘，这样可防止重复项出现\n",
    "                #  进行剪枝（a1为k项集中的一个元素，b为它的所有k-1项子集）\n",
    "                a = Lk[i] | Lk[j]  # a为frozenset()集合\n",
    "                a1 = list(a)\n",
    "                b = []\n",
    "                # 遍历取出每一个元素，转换为set，依次从a1中剔除该元素，并加入到b中\n",
    "                for q in range(len(a1)):\n",
    "                    t = [a1[q]]\n",
    "                    tt = frozenset(set(a1) - set(t))\n",
    "                    b.append(tt)\n",
    "                t = 0\n",
    "                for w in b:\n",
    "                    # 当b（即所有k-1项子集）都是Lk（频繁的）的子集，则保留，否则删除。\n",
    "                    if w in Lk:\n",
    "                        t += 1\n",
    "                if t == len(b):\n",
    "                    retList.append(b[0] | b[1])\n",
    "    return retList\n",
    " \n",
    " \n",
    "def apriori(dataSet, minSupport=0.2):\n",
    "    C1 = createC1(dataSet)\n",
    "    D = list(map(set, dataSet))  # 使用list()转换为列表\n",
    "    L1, supportData = calSupport(D, C1, minSupport)\n",
    "    L = [L1]  \n",
    "    k = 2\n",
    "    while (len(L[k - 2]) > 0):\n",
    "        Ck = aprioriGen(L[k - 2], k)\n",
    "        Lk, supK = scanD(D, Ck, minSupport)  \n",
    "        supportData.update(supK)\n",
    "        L.append(Lk)  \n",
    "        k += 1\n",
    "    del L[-1]  \n",
    "    return L, supportData  \n",
    " \n",
    "\n",
    "def getSubset(fromList, toList):\n",
    "    for i in range(len(fromList)):\n",
    "        t = [fromList[i]]\n",
    "        tt = frozenset(set(fromList) - set(t))\n",
    "        if not tt in toList:\n",
    "            toList.append(tt)\n",
    "            tt = list(tt)\n",
    "            if len(tt) > 1:\n",
    "                getSubset(tt, toList)\n",
    " \n",
    " \n",
    "def calcConf(freqSet, H, supportData, ruleList, minConf=0.7):\n",
    "    for conseq in H:\n",
    "        conf = supportData[freqSet] / supportData[freqSet - conseq]  # 计算置信度\n",
    "        lift = supportData[freqSet] / (supportData[conseq] * supportData[freqSet - conseq])\n",
    " \n",
    "        if conf >= minConf and lift > 1:\n",
    "            print(freqSet - conseq, '-->', conseq, '支持度为：', round(supportData[freqSet - conseq], 2), '置信度为：', conf,\n",
    "                  'lift值为：', round(lift, 2))\n",
    "            ruleList.append((freqSet - conseq, conseq, conf))\n",
    " \n",
    "\n",
    "def gen_rule(L, supportData, minConf=0.7):\n",
    "    bigRuleList = []\n",
    "    for i in range(1, len(L)):  \n",
    "        for freqSet in L[i]:  \n",
    "            H1 = list(freqSet)\n",
    "            all_subset = []\n",
    "            getSubset(H1, all_subset)  \n",
    "            calcConf(freqSet, all_subset, supportData, bigRuleList, minConf)\n",
    "    return bigRuleList\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    dataSet = loadDataSet()\n",
    "    L, supportData = apriori(dataSet, minSupport=0.2)\n",
    "    rule = gen_rule(L, supportData, minConf=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
